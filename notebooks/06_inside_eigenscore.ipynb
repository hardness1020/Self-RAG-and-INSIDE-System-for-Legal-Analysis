{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 06: INSIDE EigenScore Hallucination Detection\n",
    "\n",
    "This notebook demonstrates how to use INSIDE's EigenScore method for detecting hallucinations in LLM outputs.\n",
    "\n",
    "## What is EigenScore?\n",
    "\n",
    "EigenScore measures semantic consistency by analyzing the eigenvalues of the covariance matrix of sentence embeddings extracted from the LLM's internal states. Hallucinated content tends to show lower semantic diversity, resulting in different eigenvalue distributions.\n",
    "\n",
    "**Key Insight**: Lower EigenScore → Higher hallucination risk\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Import INSIDE components\n",
    "from src.inside import (\n",
    "    InternalStatesExtractor,\n",
    "    EigenScore,\n",
    "    compute_eigenscore,\n",
    "    HallucinationDetector\n",
    ")\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Internal States\n",
    "\n",
    "First, let's understand how to extract internal states from an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small model for demonstration\n",
    "model_name = \"gpt2\"  # Using GPT-2 for quick demo\n",
    "print(f\"Loading {model_name}...\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.eval()\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Model loaded. Number of layers: {model.config.n_layer}\")\n",
    "print(f\"Hidden size: {model.config.n_embd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create internal states extractor\n",
    "# For GPT-2 (12 layers), we'll use the middle layer (layer 6)\n",
    "extractor = InternalStatesExtractor(\n",
    "    model=model,\n",
    "    target_layers=[6],  # Middle layer\n",
    "    extraction_position='last',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"✓ Extractor created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Extract embeddings from a sample text\n",
    "sample_text = \"\"\"Negligence is a failure to exercise appropriate care. \n",
    "It requires duty, breach, causation, and damages. \n",
    "The plaintiff must prove all four elements.\"\"\"\n",
    "\n",
    "# Extract sentence-level embeddings\n",
    "from src.inside.internal_states import split_into_sentences\n",
    "\n",
    "sentences, boundaries = split_into_sentences(sample_text, tokenizer)\n",
    "print(f\"Text split into {len(sentences)} sentences:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"  {i}. {sent}\")\n",
    "\n",
    "# Tokenize and extract\n",
    "tokens = tokenizer.encode(sample_text, return_tensors='pt').to(device)\n",
    "embeddings = extractor.extract_embeddings(\n",
    "    input_ids=tokens,\n",
    "    sentence_boundaries=boundaries\n",
    ")\n",
    "\n",
    "layer_6_embeddings = embeddings[6]\n",
    "print(f\"\\nExtracted embeddings shape: {layer_6_embeddings.shape}\")\n",
    "print(f\"  (num_sentences={layer_6_embeddings.shape[0]}, hidden_dim={layer_6_embeddings.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Computing EigenScore\n",
    "\n",
    "Now let's compute the EigenScore from these embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute EigenScore\n",
    "scorer = EigenScore(normalize=True)\n",
    "score_details = scorer.compute(layer_6_embeddings, return_details=True)\n",
    "\n",
    "print(\"EigenScore Results:\")\n",
    "print(f\"  Score: {score_details['score']:.4f}\")\n",
    "print(f\"  Num sentences: {score_details['num_sentences']}\")\n",
    "print(f\"  Top eigenvalue: {score_details['top_eigenvalue']:.4f}\")\n",
    "print(f\"  Condition number: {score_details['condition_number']:.2f}\")\n",
    "print(f\"\\nEigenvalues (top 5):\")\n",
    "for i, ev in enumerate(score_details['eigenvalues'][:5], 1):\n",
    "    print(f\"  λ{i}: {ev:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize eigenvalue distribution\n",
    "eigenvalues = score_details['eigenvalues']\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(eigenvalues, 'o-')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.title('Eigenvalue Spectrum')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.semilogy(eigenvalues, 'o-')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue (log scale)')\n",
    "plt.title('Eigenvalue Spectrum (Log Scale)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Comparing Factual vs Hallucinated Content\n",
    "\n",
    "Let's compare EigenScores for factual and potentially hallucinated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factual example (consistent, grounded information)\n",
    "factual_text = \"\"\"Negligence requires four elements under tort law. \n",
    "First, the defendant must owe a duty of care. \n",
    "Second, there must be a breach of that duty. \n",
    "Third, the breach must cause the plaintiff's injury. \n",
    "Fourth, the plaintiff must suffer actual damages.\"\"\"\n",
    "\n",
    "# Potentially hallucinated example (inconsistent, contradictory)\n",
    "hallucinated_text = \"\"\"Negligence requires seven elements in all jurisdictions. \n",
    "The defendant's intent is crucial for establishing negligence. \n",
    "Strict liability and negligence are identical legal concepts. \n",
    "Damages are optional and not required for negligence claims. \n",
    "The duty of care was first established in 1066 AD.\"\"\"\n",
    "\n",
    "print(\"Computing EigenScores...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute EigenScore for factual text\n",
    "factual_embeddings = extractor.extract_from_generations(\n",
    "    generations=[factual_text],\n",
    "    tokenizer=tokenizer,\n",
    "    split_sentences=True\n",
    ")\n",
    "factual_score = scorer.compute(factual_embeddings[6])\n",
    "\n",
    "# Compute EigenScore for hallucinated text\n",
    "hallucinated_embeddings = extractor.extract_from_generations(\n",
    "    generations=[hallucinated_text],\n",
    "    tokenizer=tokenizer,\n",
    "    split_sentences=True\n",
    ")\n",
    "hallucinated_score = scorer.compute(hallucinated_embeddings[6])\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(f\"Factual Text EigenScore: {factual_score:.4f}\")\n",
    "print(f\"Hallucinated Text EigenScore: {hallucinated_score:.4f}\")\n",
    "print(f\"\\nDifference: {factual_score - hallucinated_score:.4f}\")\n",
    "print(f\"{'✓ Factual has higher score (as expected)' if factual_score > hallucinated_score else '⚠ Unexpected result'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Using the Hallucination Detector\n",
    "\n",
    "Now let's use the unified `HallucinationDetector` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hallucination detector\n",
    "detector = HallucinationDetector(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    target_layers=[6],\n",
    "    eigenscore_threshold=5.0,  # Example threshold\n",
    "    use_adaptive_threshold=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"✓ Hallucination detector created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "test_query = \"What are the elements of negligence?\"\n",
    "\n",
    "# Detect hallucination in factual text\n",
    "result_factual = detector.detect_from_generations(\n",
    "    query=test_query,\n",
    "    generations=[factual_text],\n",
    "    use_clipping=False,\n",
    "    return_details=True\n",
    ")\n",
    "\n",
    "print(\"Factual Text Detection:\")\n",
    "print(f\"  Is Hallucination: {result_factual['is_hallucination']}\")\n",
    "print(f\"  EigenScore: {result_factual['eigenscore']:.4f}\")\n",
    "print(f\"  Threshold: {result_factual['eigenscore_threshold']:.4f}\")\n",
    "print(f\"  Query Intent: {result_factual['query_intent']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hallucination in potentially hallucinated text\n",
    "result_hallucinated = detector.detect_from_generations(\n",
    "    query=test_query,\n",
    "    generations=[hallucinated_text],\n",
    "    use_clipping=False,\n",
    "    return_details=True\n",
    ")\n",
    "\n",
    "print(\"Potentially Hallucinated Text Detection:\")\n",
    "print(f\"  Is Hallucination: {result_hallucinated['is_hallucination']}\")\n",
    "print(f\"  EigenScore: {result_hallucinated['eigenscore']:.4f}\")\n",
    "print(f\"  Threshold: {result_hallucinated['eigenscore_threshold']:.4f}\")\n",
    "print(f\"  Query Intent: {result_hallucinated['query_intent']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Multi-Generation Detection\n",
    "\n",
    "The INSIDE paper shows that using multiple generations improves detection accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple variations of the same answer\n",
    "multiple_generations = [\n",
    "    \"Negligence requires duty, breach, causation, and damages.\",\n",
    "    \"The four elements of negligence are duty of care, breach, causation, and actual damages.\",\n",
    "    \"To prove negligence, one must show: 1) duty, 2) breach, 3) causation, 4) damages.\"\n",
    "]\n",
    "\n",
    "result_multi = detector.detect_from_generations(\n",
    "    query=test_query,\n",
    "    generations=multiple_generations,\n",
    "    use_clipping=False,\n",
    "    return_details=True\n",
    ")\n",
    "\n",
    "print(\"Multi-Generation Detection:\")\n",
    "print(f\"  Num Generations: {result_multi['num_generations']}\")\n",
    "print(f\"  Is Hallucination: {result_multi['is_hallucination']}\")\n",
    "print(f\"  EigenScore: {result_multi['eigenscore']:.4f}\")\n",
    "print(f\"  Threshold: {result_multi['eigenscore_threshold']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Calibration on Labeled Data\n",
    "\n",
    "For best results, calibrate the threshold on labeled examples from your domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example labeled data (you would have more in practice)\n",
    "factual_examples = [\n",
    "    (\"What is negligence?\", [\n",
    "        \"Negligence is a failure to exercise appropriate care.\",\n",
    "        \"It is a tort law concept involving breach of duty.\"\n",
    "    ]),\n",
    "    (\"What is strict liability?\", [\n",
    "        \"Strict liability means liability without fault.\",\n",
    "        \"No showing of negligence is required.\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "hallucinated_examples = [\n",
    "    (\"What is negligence?\", [\n",
    "        \"Negligence requires intent and malice.\",\n",
    "        \"It was invented in ancient Rome.\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Calibrate\n",
    "print(\"Calibrating threshold...\")\n",
    "calibrated_threshold = detector.calibrate(\n",
    "    factual_examples=factual_examples,\n",
    "    hallucinated_examples=hallucinated_examples,\n",
    "    percentile=10.0\n",
    ")\n",
    "\n",
    "print(f\"\\nCalibrated threshold: {calibrated_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Internal States**: How to extract sentence embeddings from LLM hidden layers\n",
    "2. **EigenScore**: How to compute semantic consistency using eigenvalue analysis\n",
    "3. **Detection**: How to detect hallucinations using EigenScore thresholds\n",
    "4. **Multi-Generation**: How multiple generations improve detection robustness\n",
    "5. **Calibration**: How to calibrate thresholds on labeled data\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Lower EigenScore → Higher hallucination risk**\n",
    "- Multiple generations provide more robust detection\n",
    "- Calibration on domain-specific data improves accuracy\n",
    "- Intent-aware thresholds adapt to different query types\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Tutorial 07: Intent-Aware Retrieval\n",
    "- Tutorial 08: Combined Self-RAG + INSIDE System"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
