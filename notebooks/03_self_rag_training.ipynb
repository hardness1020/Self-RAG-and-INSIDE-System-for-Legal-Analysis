{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Self-RAG Models\n",
    "\n",
    "Train critic and generator models using QLoRA for Self-RAG system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before training:\n",
    "1. ✅ Documents indexed (from notebook 02)\n",
    "2. ✅ Training data prepared (from notebook 01)\n",
    "3. ⚠️ Training requires significant compute (GPU recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate Training Labels\n",
    "\n",
    "Generate reflection token labels for Q&A data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Generate labels using rule-based approach\n",
    "uv run python -m src.training.generate_labels \\\n",
    "    --input ../data/samples/sample_qa_data.json \\\n",
    "    --output-dir ../data/training \\\n",
    "    --num-samples 10\n",
    "\n",
    "echo \"✅ Labels generated!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train Critic Model\n",
    "\n",
    "Train the critic model to predict reflection tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Train critic (reduce epochs for testing)\n",
    "uv run python -m src.training.train_critic_qlora \\\n",
    "    --config ../configs/critic_config.yaml\n",
    "\n",
    "echo \"✅ Critic model trained!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Generator Model\n",
    "\n",
    "Train the generator model with augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Train generator with critic weights\n",
    "uv run python -m src.training.train_generator_qlora \\\n",
    "    --config ../configs/generator_config.yaml \\\n",
    "    --critic-weights ../models/critic_lora/final\n",
    "\n",
    "echo \"✅ Generator model trained!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test Trained Models\n",
    "\n",
    "Quick test of the trained Self-RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.self_rag.inference import load_pipeline_from_config\n",
    "\n",
    "# Load complete pipeline\n",
    "pipeline = load_pipeline_from_config(\n",
    "    retrieval_config_path='../configs/retrieval_config.yaml',\n",
    "    generator_config_path='../configs/generator_config.yaml',\n",
    "    retriever_index_dir='../data/embeddings',\n",
    "    generator_weights_path='../models/generator_lora/final',\n",
    ")\n",
    "\n",
    "print(\"✅ Pipeline loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test question\n",
    "question = \"What are the elements of negligence?\"\n",
    "\n",
    "result = pipeline.answer_question(question)\n",
    "\n",
    "print(f\"Question: {question}\\n\")\n",
    "print(f\"Answer: {result['answer']}\\n\")\n",
    "print(f\"Reflection: {result['reflection']}\\n\")\n",
    "print(f\"Score: {result['score']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Tips\n",
    "\n",
    "### For CPU Training:\n",
    "- Reduce `per_device_train_batch_size` to 1-2\n",
    "- Increase `gradient_accumulation_steps`\n",
    "- Reduce `num_train_epochs` to 1 for testing\n",
    "- Use smaller models if available\n",
    "\n",
    "### For GPU Training:\n",
    "- Use larger batch sizes (4-8)\n",
    "- Enable `fp16` or `bf16` in config\n",
    "- Monitor GPU memory usage\n",
    "\n",
    "### Monitoring:\n",
    "- Check `models/*/logs/` for TensorBoard logs\n",
    "- Watch training loss decrease\n",
    "- Save checkpoints frequently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Training complete!\n",
    "- ✅ Generated training labels\n",
    "- ✅ Trained critic model\n",
    "- ✅ Trained generator model\n",
    "- ✅ Tested Self-RAG pipeline\n",
    "\n",
    "**Next:** Proceed to `04_evaluation.ipynb` to evaluate performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
