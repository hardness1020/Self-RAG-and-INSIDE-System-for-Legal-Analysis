{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-RAG Interactive Demo\n",
    "\n",
    "Interactive demonstration of the complete Self-RAG system for legal analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.self_rag.inference import load_pipeline_from_config\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Complete Self-RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Self-RAG pipeline...\n",
      "Loading Self-RAG Pipeline...\n",
      "\n",
      "1. Loading retriever...\n",
      "Loading embedding model: sentence-transformers/all-mpnet-base-v2\n",
      "Model loaded on mps\n",
      "Embedding dimension: 768\n",
      "   Loading index from ../data/embeddings\n",
      "Using CPU index\n",
      "Created IndexFlatIP index with dimension 768\n",
      "Index loaded from ../data/embeddings/faiss_index.faiss\n",
      "Total documents in index: 10\n",
      "Documents loaded from ../data/embeddings/documents.pkl\n",
      "   Index loaded: 10 documents\n",
      "\n",
      "2. Loading generator...\n",
      "Loading generator model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "Warning: 4-bit quantization not supported on macOS. Loading model in full precision.\n",
      "Loading LoRA weights from ../models/generator_lora/final\n",
      "Generator model loaded successfully\n",
      "MPS cache cleared\n",
      "\n",
      "3. Loading critic model for reflection tokens...\n",
      "Loading model: Qwen/Qwen2.5-0.5B-Instruct\n",
      "Warning: 4-bit quantization not supported on macOS. Loading model in full precision.\n",
      "Loading LoRA weights from ../models/critic_lora/final\n",
      "Model loaded successfully\n",
      "MPS cache cleared\n",
      "   Critic model loaded successfully\n",
      "\n",
      "Pipeline loaded successfully!\n",
      "‚úÖ Pipeline loaded!\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline\n",
    "print(\"Loading Self-RAG pipeline...\")\n",
    "\n",
    "pipeline = load_pipeline_from_config(\n",
    "    retrieval_config_path='../configs/retrieval_config.yaml',\n",
    "    generator_config_path='../configs/generator_config.yaml',\n",
    "    retriever_index_dir='../data/embeddings',\n",
    "    generator_weights_path='../models/generator_lora/final',\n",
    "    critic_weights_path='../models/critic_lora/final',\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Pipeline loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test with Example Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_question(question):\n",
    "    \"\"\"Demonstrate Self-RAG with a question.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Get answer\n",
    "    result = pipeline.answer_question(question)\n",
    "    \n",
    "    # Display formatted response\n",
    "    formatted = pipeline.format_response(\n",
    "        result,\n",
    "        include_passages=True,\n",
    "        include_reflection=True\n",
    "    )\n",
    "    \n",
    "    print(formatted)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Question: What are the four elements of negligence?\n",
      "================================================================================\n",
      "\n",
      "Question: What are the four elements of negligence?\n",
      "\n",
      "Answer: Negligence is a legal concept that requires proof of three elements. These elements include:\n",
      "- Duty of care\n",
      "- Breach of duty\n",
      "- Damages.\n",
      "The first two elements, \"duty of care\" and \"breach of duty,\" are required to prove negligence. The third element, \"damages,\" is what the plaintiff seeks in compensation for their injuries or losses.\n",
      "In order to establish negligence, the plaintiff must show that they were exposed to an unreasonable risk of harm. This means that there was a reasonable person who could have foreseen the risk but failed to take steps to mitigate it. For example, if someone was driving a car and ran a red light, they would be considered negligent because they had no reasonable excuse for not stopping.\n",
      "It's important to note that negligence does not necessarily mean that the defendant caused the injury or loss. In some cases, negligence may be used as a defense against liability. For example, if a manufacturer knew about a defect in a product but still sold it to consumers, they may be able to argue that they did not know about the defect and therefore should not be held liable for any injuries caused by it.\n",
      "Overall, negligence is a complex legal concept that requires careful consideration of all relevant factors. It's important to\n",
      "\n",
      "\n",
      "Self-Evaluation:\n",
      "  RETRIEVE: [Retrieve]\n",
      "  ISUSE: [Utility:5]\n",
      "  Overall Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Basic negligence question\n",
    "result1 = demo_question(\"What are the four elements of negligence?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Question: What is res ipsa loquitur and when does it apply?\n",
      "================================================================================\n",
      "\n",
      "Question: What is res ipsa loquitur and when does it apply?\n",
      "\n",
      "Answer: Res ipsa loquitur applies to situations where the plaintiff's damages are caused by an event that was foreseeable but not reasonably anticipated. The doctrine requires proof of foreseeability, which means that the defendant must have known or should have known about the risk involved in the act.\n",
      "The doctrine has been applied in many jurisdictions, including California, New York, Pennsylvania, and Texas. In some cases, courts may also consider whether the defendant had a duty to warn of the risk involved in the act.\n",
      "In general, res ipsa loquitur is only applicable if the plaintiff can prove that they were unaware of the risk involved in the act. If the plaintiff can prove that they were aware of the risk, then the defendant cannot be held liable for their damages.\n",
      "It is important to note that res ipsa loquitur is not always applicable. For example, in certain types of negligence cases, such as those involving defective products, there may be no reasonable expectation of foreseeability. In these cases, the court may still consider whether the defendant had a duty to warn of the risk involved in the act.\n",
      "Overall, res ipsa loquitur is a useful tool for holding defendants responsible for damages caused by negligent acts. However, it is important to carefully consider the facts of each\n",
      "\n",
      "\n",
      "Self-Evaluation:\n",
      "  RETRIEVE: [Retrieve]\n",
      "  ISUSE: [Utility:5]\n",
      "  Overall Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Specific doctrine\n",
    "result2 = demo_question(\"What is res ipsa loquitur and when does it apply?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Question: What is the difference between comparative negligence and assumption of risk?\n",
      "================================================================================\n",
      "\n",
      "Question: What is the difference between comparative negligence and assumption of risk?\n",
      "\n",
      "Answer: Comparative negligence means that a plaintiff can recover only to the extent that the defendant's fault was more than 50% greater than the plaintiff's. Assumption of risk means that the plaintiff must prove that they were aware of the risks involved in their actions.\n",
      "The key difference between these two concepts is that comparative negligence applies when one party is found liable for an accident, while assumption of risk applies when one party is not liable for an accident.\n",
      "In general, it is easier to prove comparative negligence because it requires proving that the defendant's fault was greater than 50%. However, if you are sued for an accident where the other party was at fault, then you may be able to prove assumption of risk by showing that you were aware of the risks involved in your actions.\n",
      "It is important to note that both concepts apply equally to personal injury cases. If you have been injured in an accident and believe that you should be compensated for your damages, you should consult with an attorney who specializes in personal injury law to determine which concept is applicable to your case.<|endoftext|>A company has a policy requiring employees to wear protective gear during work hours. The company also provides training on how to use this equipment correctly. An employee accidentally falls off a ladder while wearing the protective gear. Can the\n",
      "\n",
      "\n",
      "Self-Evaluation:\n",
      "  RETRIEVE: [Retrieve]\n",
      "  ISUSE: [Utility:5]\n",
      "  Overall Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Defenses\n",
    "result3 = demo_question(\"What is the difference between comparative negligence and assumption of risk?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Interactive Question & Answer\n",
    "\n",
    "Enter your own questions below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Interactive mode\n",
    "# your_question = input(\"Enter your legal question: \")\n",
    "\n",
    "# if your_question:\n",
    "#     result = demo_question(your_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Reflection Tokens\n",
    "\n",
    "Examine the self-verification in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reflection Token Analysis:\n",
      "==================================================\n",
      "\n",
      "üìç Retrieve: [Retrieve]\n",
      "   ‚Üí Did the model decide to retrieve evidence?\n",
      "\n",
      "üîç ISREL (Relevance): None\n",
      "   ‚Üí Is the retrieved passage relevant?\n",
      "\n",
      "‚úì ISSUP (Support): None\n",
      "   ‚Üí Is the answer supported by evidence?\n",
      "   ‚Üí Hallucination detection!\n",
      "\n",
      "‚≠ê ISUSE (Utility): [Utility:5]\n",
      "   ‚Üí Overall response quality (1-5)\n",
      "\n",
      "üìä Overall Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "def analyze_reflection(result):\n",
    "    \"\"\"Analyze reflection tokens from a result.\"\"\"\n",
    "    reflection = result['reflection']\n",
    "    \n",
    "    print(\"\\nReflection Token Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(f\"\\nüìç Retrieve: {reflection.get('retrieve', 'N/A')}\")\n",
    "    print(\"   ‚Üí Did the model decide to retrieve evidence?\")\n",
    "    \n",
    "    print(f\"\\nüîç ISREL (Relevance): {reflection.get('isrel', 'N/A')}\")\n",
    "    print(\"   ‚Üí Is the retrieved passage relevant?\")\n",
    "    \n",
    "    print(f\"\\n‚úì ISSUP (Support): {reflection.get('issup', 'N/A')}\")\n",
    "    print(\"   ‚Üí Is the answer supported by evidence?\")\n",
    "    print(\"   ‚Üí Hallucination detection!\")\n",
    "    \n",
    "    print(f\"\\n‚≠ê ISUSE (Utility): {reflection.get('isuse', 'N/A')}\")\n",
    "    print(\"   ‚Üí Overall response quality (1-5)\")\n",
    "    \n",
    "    print(f\"\\nüìä Overall Score: {result['score']:.2f}\")\n",
    "    \n",
    "    # Hallucination check - Fixed to handle None values\n",
    "    support = reflection.get('issup') or ''\n",
    "    if 'No Support' in support:\n",
    "        print(\"\\n‚ö†Ô∏è  WARNING: Potential hallucination detected!\")\n",
    "    elif 'Fully Supported' in support:\n",
    "        print(\"\\n‚úÖ Response is fully supported by evidence\")\n",
    "\n",
    "# Analyze previous results\n",
    "analyze_reflection(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Processing\n",
    "\n",
    "Process multiple questions at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch Processing Summary:\n",
      "================================================================================\n",
      "\n",
      "1. What is causation in negligence?\n",
      "   Score: 1.00\n",
      "   Support: None\n",
      "   Answer: The concept of causation is a key element in negligence cases. Negligence occurs...\n",
      "\n",
      "2. What damages can be recovered?\n",
      "   Score: 1.00\n",
      "   Support: None\n",
      "   Answer: Damages are recoverable in a personal injury case if the plaintiff has suffered ...\n",
      "\n",
      "3. What is professional malpractice?\n",
      "   Score: 1.00\n",
      "   Support: None\n",
      "   Answer: Professional malpractice occurs when a healthcare provider or other health care ...\n"
     ]
    }
   ],
   "source": [
    "# Batch questions\n",
    "questions = [\n",
    "    \"What is causation in negligence?\",\n",
    "    \"What damages can be recovered?\",\n",
    "    \"What is professional malpractice?\",\n",
    "]\n",
    "\n",
    "# Process all\n",
    "results = pipeline.answer_batch(questions)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nBatch Processing Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for i, (q, r) in enumerate(zip(questions, results), 1):\n",
    "    print(f\"\\n{i}. {q}\")\n",
    "    print(f\"   Score: {r['score']:.2f}\")\n",
    "    print(f\"   Support: {r['reflection'].get('issup', 'N/A')}\")\n",
    "    print(f\"   Answer: {r['answer'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results saved to ../results/demo_results.json\n"
     ]
    }
   ],
   "source": [
    "# Save results for analysis\n",
    "output = {\n",
    "    'questions': questions,\n",
    "    'results': [\n",
    "        {\n",
    "            'question': r['question'],\n",
    "            'answer': r['answer'],\n",
    "            'reflection': r['reflection'],\n",
    "            'score': r['score']\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    "}\n",
    "\n",
    "with open('../results/demo_results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Results saved to ../results/demo_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Demo complete!\n",
    "- ‚úÖ Tested Self-RAG on legal questions\n",
    "- ‚úÖ Analyzed reflection tokens\n",
    "- ‚úÖ Demonstrated hallucination detection\n",
    "- ‚úÖ Processed batch questions\n",
    "- ‚úÖ Exported results\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Adaptive Retrieval**: Model decides when to retrieve evidence\n",
    "2. **Self-Verification**: Reflection tokens provide quality assessment\n",
    "3. **Hallucination Detection**: ISSUP token identifies unsupported claims\n",
    "4. **Transparency**: See exactly why the model made each decision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-rag-legal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
